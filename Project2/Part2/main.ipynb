{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Language = \"English\"\n",
    "Language = \"Chinese\"\n",
    "mode = \"train\"\n",
    "# mode = \"test\"\n",
    "param_num = 1\n",
    "\n",
    "# 如果要进行test，先把test.txt放到对应文件夹下，然后把mode改为\"test\"再运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-26 17:25:24,355 P7004 INFO train dataset size: 3820\n",
      "2023-11-26 17:25:24,356 P7004 INFO valid dataset size: 462\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from Part1.dataprocess import data_process, set_log, combine_data\n",
    "from sklearn_crf import sent2features\n",
    "\n",
    "\n",
    "set_log(None)\n",
    "train_data, valid_data, test_data = data_process(f\"../NER/{Language}\", mode=mode)\n",
    "\n",
    "\n",
    "x_train = [sent2features(sentence, param_num) for sentence, _ in train_data]\n",
    "y_train = [label for _, label in train_data]\n",
    "x_valid = [sent2features(sentence, param_num) for sentence, _ in valid_data]\n",
    "y_valid = [label for _, label in valid_data]\n",
    "if mode == \"test\":\n",
    "    x_test = [sent2features(sentence, param_num) for sentence, _ in test_data]\n",
    "    y_test = [label for _, label in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 3820/3820 [00:00<00:00, 9015.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 24925\n",
      "Seconds required: 0.096\n",
      "\n",
      "Averaged perceptron\n",
      "max_iterations: 300\n",
      "epsilon: 0.000000\n",
      "\n",
      "Iter 1   time=0.14  loss=555.92   feature_norm=650.02\n",
      "Iter 2   time=0.13  loss=291.97   feature_norm=797.79\n",
      "Iter 3   time=0.13  loss=267.93   feature_norm=906.39\n",
      "Iter 4   time=0.12  loss=244.72   feature_norm=1002.91\n",
      "Iter 5   time=0.12  loss=227.90   feature_norm=1084.57\n",
      "Iter 6   time=0.12  loss=194.15   feature_norm=1157.83\n",
      "Iter 7   time=0.12  loss=186.78   feature_norm=1221.38\n",
      "Iter 8   time=0.12  loss=171.89   feature_norm=1277.44\n",
      "Iter 9   time=0.12  loss=148.34   feature_norm=1327.83\n",
      "Iter 10  time=0.12  loss=158.30   feature_norm=1373.10\n",
      "Iter 11  time=0.12  loss=151.62   feature_norm=1415.29\n",
      "Iter 12  time=0.12  loss=157.66   feature_norm=1456.10\n",
      "Iter 13  time=0.12  loss=138.66   feature_norm=1495.42\n",
      "Iter 14  time=0.12  loss=127.59   feature_norm=1531.70\n",
      "Iter 15  time=0.12  loss=140.47   feature_norm=1566.44\n",
      "Iter 16  time=0.12  loss=138.00   feature_norm=1599.73\n",
      "Iter 17  time=0.12  loss=125.41   feature_norm=1632.00\n",
      "Iter 18  time=0.12  loss=117.81   feature_norm=1662.77\n",
      "Iter 19  time=0.12  loss=110.82   feature_norm=1691.78\n",
      "Iter 20  time=0.12  loss=110.99   feature_norm=1719.54\n",
      "Iter 21  time=0.12  loss=104.11   feature_norm=1745.87\n",
      "Iter 22  time=0.12  loss=121.31   feature_norm=1771.19\n",
      "Iter 23  time=0.12  loss=98.41    feature_norm=1795.67\n",
      "Iter 24  time=0.12  loss=86.80    feature_norm=1818.94\n",
      "Iter 25  time=0.12  loss=96.52    feature_norm=1841.23\n",
      "Iter 26  time=0.12  loss=109.99   feature_norm=1863.18\n",
      "Iter 27  time=0.12  loss=95.97    feature_norm=1884.88\n",
      "Iter 28  time=0.12  loss=106.22   feature_norm=1906.55\n",
      "Iter 29  time=0.11  loss=94.37    feature_norm=1927.85\n",
      "Iter 30  time=0.12  loss=96.10    feature_norm=1948.55\n",
      "Iter 31  time=0.12  loss=88.60    feature_norm=1968.67\n",
      "Iter 32  time=0.12  loss=88.44    feature_norm=1988.32\n",
      "Iter 33  time=0.11  loss=74.63    feature_norm=2007.45\n",
      "Iter 34  time=0.12  loss=89.69    feature_norm=2026.15\n",
      "Iter 35  time=0.11  loss=95.41    feature_norm=2044.53\n",
      "Iter 36  time=0.12  loss=86.81    feature_norm=2062.67\n",
      "Iter 37  time=0.11  loss=89.33    feature_norm=2080.62\n",
      "Iter 38  time=0.11  loss=90.57    feature_norm=2098.35\n",
      "Iter 39  time=0.11  loss=88.43    feature_norm=2115.75\n",
      "Iter 40  time=0.12  loss=77.36    feature_norm=2132.85\n",
      "Iter 41  time=0.11  loss=67.38    feature_norm=2149.40\n",
      "Iter 42  time=0.11  loss=70.29    feature_norm=2165.54\n",
      "Iter 43  time=0.12  loss=93.79    feature_norm=2181.43\n",
      "Iter 44  time=0.12  loss=70.75    feature_norm=2197.33\n",
      "Iter 45  time=0.11  loss=81.50    feature_norm=2212.91\n",
      "Iter 46  time=0.12  loss=71.18    feature_norm=2228.32\n",
      "Iter 47  time=0.11  loss=62.63    feature_norm=2243.33\n",
      "Iter 48  time=0.11  loss=70.61    feature_norm=2258.06\n",
      "Iter 49  time=0.11  loss=81.04    feature_norm=2272.59\n",
      "Iter 50  time=0.11  loss=61.73    feature_norm=2286.81\n",
      "Iter 51  time=0.11  loss=76.91    feature_norm=2300.85\n",
      "Iter 52  time=0.12  loss=75.47    feature_norm=2314.74\n",
      "Iter 53  time=0.11  loss=67.02    feature_norm=2328.37\n",
      "Iter 54  time=0.12  loss=69.65    feature_norm=2341.78\n",
      "Iter 55  time=0.11  loss=62.37    feature_norm=2354.98\n",
      "Iter 56  time=0.12  loss=61.58    feature_norm=2368.00\n",
      "Iter 57  time=0.11  loss=55.28    feature_norm=2380.72\n",
      "Iter 58  time=0.11  loss=72.68    feature_norm=2393.25\n",
      "Iter 59  time=0.11  loss=62.49    feature_norm=2405.62\n",
      "Iter 60  time=0.11  loss=62.70    feature_norm=2417.84\n",
      "Iter 61  time=0.11  loss=53.07    feature_norm=2429.83\n",
      "Iter 62  time=0.11  loss=63.14    feature_norm=2441.60\n",
      "Iter 63  time=0.11  loss=61.21    feature_norm=2453.23\n",
      "Iter 64  time=0.11  loss=60.55    feature_norm=2464.68\n",
      "Iter 65  time=0.11  loss=63.63    feature_norm=2476.02\n",
      "Iter 66  time=0.11  loss=60.68    feature_norm=2487.18\n",
      "Iter 67  time=0.11  loss=58.99    feature_norm=2498.23\n",
      "Iter 68  time=0.11  loss=71.29    feature_norm=2509.17\n",
      "Iter 69  time=0.11  loss=51.39    feature_norm=2520.04\n",
      "Iter 70  time=0.11  loss=64.31    feature_norm=2530.83\n",
      "Iter 71  time=0.12  loss=62.61    feature_norm=2541.65\n",
      "Iter 72  time=0.11  loss=50.53    feature_norm=2552.37\n",
      "Iter 73  time=0.11  loss=50.68    feature_norm=2562.92\n",
      "Iter 74  time=0.11  loss=50.71    feature_norm=2573.32\n",
      "Iter 75  time=0.11  loss=64.93    feature_norm=2583.65\n",
      "Iter 76  time=0.11  loss=53.20    feature_norm=2593.89\n",
      "Iter 77  time=0.11  loss=56.41    feature_norm=2604.02\n",
      "Iter 78  time=0.11  loss=52.58    feature_norm=2614.03\n",
      "Iter 79  time=0.11  loss=49.62    feature_norm=2623.92\n",
      "Iter 80  time=0.11  loss=54.91    feature_norm=2633.70\n",
      "Iter 81  time=0.11  loss=53.84    feature_norm=2643.38\n",
      "Iter 82  time=0.11  loss=48.32    feature_norm=2653.00\n",
      "Iter 83  time=0.11  loss=61.52    feature_norm=2662.55\n",
      "Iter 84  time=0.11  loss=56.85    feature_norm=2672.04\n",
      "Iter 85  time=0.11  loss=45.25    feature_norm=2681.48\n",
      "Iter 86  time=0.11  loss=49.86    feature_norm=2690.83\n",
      "Iter 87  time=0.11  loss=45.00    feature_norm=2700.06\n",
      "Iter 88  time=0.11  loss=47.69    feature_norm=2709.18\n",
      "Iter 89  time=0.11  loss=48.32    feature_norm=2718.18\n",
      "Iter 90  time=0.11  loss=51.93    feature_norm=2727.10\n",
      "Iter 91  time=0.11  loss=55.30    feature_norm=2735.93\n",
      "Iter 92  time=0.11  loss=51.62    feature_norm=2744.72\n",
      "Iter 93  time=0.11  loss=58.41    feature_norm=2753.50\n",
      "Iter 94  time=0.11  loss=48.56    feature_norm=2762.21\n",
      "Iter 95  time=0.11  loss=54.33    feature_norm=2770.88\n",
      "Iter 96  time=0.11  loss=44.82    feature_norm=2779.46\n",
      "Iter 97  time=0.11  loss=49.69    feature_norm=2787.97\n",
      "Iter 98  time=0.11  loss=53.16    feature_norm=2796.42\n",
      "Iter 99  time=0.11  loss=50.80    feature_norm=2804.83\n",
      "Iter 100 time=0.11  loss=50.92    feature_norm=2813.21\n",
      "Iter 101 time=0.11  loss=52.29    feature_norm=2821.52\n",
      "Iter 102 time=0.11  loss=50.02    feature_norm=2829.80\n",
      "Iter 103 time=0.11  loss=53.48    feature_norm=2838.05\n",
      "Iter 104 time=0.11  loss=47.59    feature_norm=2846.30\n",
      "Iter 105 time=0.11  loss=43.46    feature_norm=2854.50\n",
      "Iter 106 time=0.11  loss=43.48    feature_norm=2862.64\n",
      "Iter 107 time=0.11  loss=37.01    feature_norm=2870.69\n",
      "Iter 108 time=0.11  loss=40.90    feature_norm=2878.67\n",
      "Iter 109 time=0.11  loss=48.59    feature_norm=2886.58\n",
      "Iter 110 time=0.11  loss=39.76    feature_norm=2894.44\n",
      "Iter 111 time=0.11  loss=50.23    feature_norm=2902.23\n",
      "Iter 112 time=0.11  loss=39.02    feature_norm=2909.96\n",
      "Iter 113 time=0.11  loss=44.15    feature_norm=2917.61\n",
      "Iter 114 time=0.11  loss=48.61    feature_norm=2925.25\n",
      "Iter 115 time=0.11  loss=45.61    feature_norm=2932.83\n",
      "Iter 116 time=0.11  loss=42.18    feature_norm=2940.35\n",
      "Iter 117 time=0.11  loss=39.15    feature_norm=2947.81\n",
      "Iter 118 time=0.11  loss=34.73    feature_norm=2955.20\n",
      "Iter 119 time=0.11  loss=43.88    feature_norm=2962.53\n",
      "Iter 120 time=0.11  loss=39.89    feature_norm=2969.79\n",
      "Iter 121 time=0.11  loss=30.14    feature_norm=2977.01\n",
      "Iter 122 time=0.11  loss=39.82    feature_norm=2984.16\n",
      "Iter 123 time=0.11  loss=37.10    feature_norm=2991.24\n",
      "Iter 124 time=0.11  loss=45.54    feature_norm=2998.28\n",
      "Iter 125 time=0.11  loss=30.51    feature_norm=3005.27\n",
      "Iter 126 time=0.11  loss=38.10    feature_norm=3012.18\n",
      "Iter 127 time=0.11  loss=36.61    feature_norm=3019.04\n",
      "Iter 128 time=0.11  loss=52.00    feature_norm=3025.88\n",
      "Iter 129 time=0.11  loss=41.40    feature_norm=3032.70\n",
      "Iter 130 time=0.11  loss=41.17    feature_norm=3039.46\n",
      "Iter 131 time=0.11  loss=37.20    feature_norm=3046.16\n",
      "Iter 132 time=0.11  loss=40.88    feature_norm=3052.82\n",
      "Iter 133 time=0.11  loss=44.14    feature_norm=3059.43\n",
      "Iter 134 time=0.11  loss=40.29    feature_norm=3066.00\n",
      "Iter 135 time=0.11  loss=39.06    feature_norm=3072.53\n",
      "Iter 136 time=0.11  loss=35.52    feature_norm=3079.03\n",
      "Iter 137 time=0.11  loss=52.09    feature_norm=3085.54\n",
      "Iter 138 time=0.11  loss=47.09    feature_norm=3092.03\n",
      "Iter 139 time=0.11  loss=42.14    feature_norm=3098.49\n",
      "Iter 140 time=0.11  loss=37.14    feature_norm=3104.91\n",
      "Iter 141 time=0.11  loss=39.38    feature_norm=3111.31\n",
      "Iter 142 time=0.11  loss=34.44    feature_norm=3117.66\n",
      "Iter 143 time=0.11  loss=40.61    feature_norm=3123.96\n",
      "Iter 144 time=0.11  loss=29.82    feature_norm=3130.22\n",
      "Iter 145 time=0.11  loss=28.57    feature_norm=3136.42\n",
      "Iter 146 time=0.11  loss=39.01    feature_norm=3142.58\n",
      "Iter 147 time=0.11  loss=40.89    feature_norm=3148.73\n",
      "Iter 148 time=0.11  loss=29.43    feature_norm=3154.84\n",
      "Iter 149 time=0.11  loss=34.20    feature_norm=3160.90\n",
      "Iter 150 time=0.11  loss=36.12    feature_norm=3166.93\n",
      "Iter 151 time=0.11  loss=32.55    feature_norm=3172.93\n",
      "Iter 152 time=0.11  loss=39.88    feature_norm=3178.90\n",
      "Iter 153 time=0.11  loss=26.37    feature_norm=3184.83\n",
      "Iter 154 time=0.11  loss=28.01    feature_norm=3190.70\n",
      "Iter 155 time=0.11  loss=34.61    feature_norm=3196.54\n",
      "Iter 156 time=0.11  loss=29.27    feature_norm=3202.34\n",
      "Iter 157 time=0.11  loss=37.56    feature_norm=3208.08\n",
      "Iter 158 time=0.11  loss=30.03    feature_norm=3213.81\n",
      "Iter 159 time=0.11  loss=25.34    feature_norm=3219.48\n",
      "Iter 160 time=0.11  loss=28.49    feature_norm=3225.10\n",
      "Iter 161 time=0.11  loss=26.40    feature_norm=3230.68\n",
      "Iter 162 time=0.11  loss=22.35    feature_norm=3236.23\n",
      "Iter 163 time=0.11  loss=26.71    feature_norm=3241.73\n",
      "Iter 164 time=0.11  loss=39.33    feature_norm=3247.20\n",
      "Iter 165 time=0.11  loss=26.44    feature_norm=3252.65\n",
      "Iter 166 time=0.11  loss=37.73    feature_norm=3258.05\n",
      "Iter 167 time=0.11  loss=30.49    feature_norm=3263.43\n",
      "Iter 168 time=0.11  loss=37.49    feature_norm=3268.78\n",
      "Iter 169 time=0.11  loss=29.26    feature_norm=3274.12\n",
      "Iter 170 time=0.11  loss=30.16    feature_norm=3279.43\n",
      "Iter 171 time=0.11  loss=27.30    feature_norm=3284.70\n",
      "Iter 172 time=0.10  loss=25.88    feature_norm=3289.94\n",
      "Iter 173 time=0.11  loss=35.89    feature_norm=3295.14\n",
      "Iter 174 time=0.11  loss=30.00    feature_norm=3300.32\n",
      "Iter 175 time=0.11  loss=29.80    feature_norm=3305.50\n",
      "Iter 176 time=0.11  loss=24.95    feature_norm=3310.64\n",
      "Iter 177 time=0.11  loss=28.17    feature_norm=3315.76\n",
      "Iter 178 time=0.11  loss=27.79    feature_norm=3320.83\n",
      "Iter 179 time=0.11  loss=34.57    feature_norm=3325.89\n",
      "Iter 180 time=0.11  loss=28.66    feature_norm=3330.92\n",
      "Iter 181 time=0.10  loss=28.86    feature_norm=3335.92\n",
      "Iter 182 time=0.11  loss=23.94    feature_norm=3340.91\n",
      "Iter 183 time=0.11  loss=23.72    feature_norm=3345.85\n",
      "Iter 184 time=0.11  loss=23.70    feature_norm=3350.76\n",
      "Iter 185 time=0.11  loss=26.97    feature_norm=3355.64\n",
      "Iter 186 time=0.11  loss=36.12    feature_norm=3360.49\n",
      "Iter 187 time=0.11  loss=31.68    feature_norm=3365.32\n",
      "Iter 188 time=0.11  loss=29.24    feature_norm=3370.13\n",
      "Iter 189 time=0.11  loss=25.48    feature_norm=3374.91\n",
      "Iter 190 time=0.11  loss=29.84    feature_norm=3379.66\n",
      "Iter 191 time=0.11  loss=33.31    feature_norm=3384.39\n",
      "Iter 192 time=0.10  loss=23.56    feature_norm=3389.09\n",
      "Iter 193 time=0.11  loss=21.21    feature_norm=3393.75\n",
      "Iter 194 time=0.11  loss=21.59    feature_norm=3398.39\n",
      "Iter 195 time=0.11  loss=27.25    feature_norm=3403.00\n",
      "Iter 196 time=0.10  loss=21.21    feature_norm=3407.58\n",
      "Iter 197 time=0.10  loss=20.28    feature_norm=3412.12\n",
      "Iter 198 time=0.11  loss=33.70    feature_norm=3416.65\n",
      "Iter 199 time=0.11  loss=26.80    feature_norm=3421.16\n",
      "Iter 200 time=0.11  loss=30.10    feature_norm=3425.66\n",
      "Iter 201 time=0.10  loss=22.67    feature_norm=3430.14\n",
      "Iter 202 time=0.11  loss=21.58    feature_norm=3434.58\n",
      "Iter 203 time=0.11  loss=31.89    feature_norm=3439.01\n",
      "Iter 204 time=0.11  loss=28.82    feature_norm=3443.41\n",
      "Iter 205 time=0.11  loss=27.94    feature_norm=3447.80\n",
      "Iter 206 time=0.11  loss=21.68    feature_norm=3452.18\n",
      "Iter 207 time=0.11  loss=24.10    feature_norm=3456.53\n",
      "Iter 208 time=0.11  loss=29.84    feature_norm=3460.87\n",
      "Iter 209 time=0.11  loss=23.83    feature_norm=3465.19\n",
      "Iter 210 time=0.10  loss=20.44    feature_norm=3469.49\n",
      "Iter 211 time=0.11  loss=24.33    feature_norm=3473.76\n",
      "Iter 212 time=0.11  loss=28.79    feature_norm=3478.03\n",
      "Iter 213 time=0.11  loss=26.51    feature_norm=3482.27\n",
      "Iter 214 time=0.11  loss=26.96    feature_norm=3486.50\n",
      "Iter 215 time=0.11  loss=24.94    feature_norm=3490.71\n",
      "Iter 216 time=0.11  loss=29.85    feature_norm=3494.90\n",
      "Iter 217 time=0.10  loss=23.68    feature_norm=3499.08\n",
      "Iter 218 time=0.11  loss=25.71    feature_norm=3503.23\n",
      "Iter 219 time=0.11  loss=26.17    feature_norm=3507.37\n",
      "Iter 220 time=0.10  loss=21.90    feature_norm=3511.49\n",
      "Iter 221 time=0.10  loss=20.69    feature_norm=3515.59\n",
      "Iter 222 time=0.10  loss=21.03    feature_norm=3519.66\n",
      "Iter 223 time=0.11  loss=23.82    feature_norm=3523.72\n",
      "Iter 224 time=0.11  loss=21.87    feature_norm=3527.76\n",
      "Iter 225 time=0.11  loss=20.17    feature_norm=3531.77\n",
      "Iter 226 time=0.11  loss=25.58    feature_norm=3535.77\n",
      "Iter 227 time=0.10  loss=20.57    feature_norm=3539.76\n",
      "Iter 228 time=0.11  loss=24.94    feature_norm=3543.73\n",
      "Iter 229 time=0.11  loss=27.39    feature_norm=3547.68\n",
      "Iter 230 time=0.11  loss=24.00    feature_norm=3551.62\n",
      "Iter 231 time=0.11  loss=26.30    feature_norm=3555.54\n",
      "Iter 232 time=0.11  loss=21.63    feature_norm=3559.45\n",
      "Iter 233 time=0.11  loss=25.90    feature_norm=3563.34\n",
      "Iter 234 time=0.11  loss=23.75    feature_norm=3567.22\n",
      "Iter 235 time=0.10  loss=25.96    feature_norm=3571.08\n",
      "Iter 236 time=0.10  loss=25.80    feature_norm=3574.92\n",
      "Iter 237 time=0.11  loss=26.71    feature_norm=3578.76\n",
      "Iter 238 time=0.11  loss=20.94    feature_norm=3582.57\n",
      "Iter 239 time=0.10  loss=23.78    feature_norm=3586.37\n",
      "Iter 240 time=0.11  loss=19.36    feature_norm=3590.15\n",
      "Iter 241 time=0.10  loss=21.77    feature_norm=3593.92\n",
      "Iter 242 time=0.11  loss=20.76    feature_norm=3597.66\n",
      "Iter 243 time=0.11  loss=29.55    feature_norm=3601.40\n",
      "Iter 244 time=0.10  loss=17.76    feature_norm=3605.12\n",
      "Iter 245 time=0.11  loss=26.35    feature_norm=3608.83\n",
      "Iter 246 time=0.11  loss=20.36    feature_norm=3612.52\n",
      "Iter 247 time=0.10  loss=23.10    feature_norm=3616.20\n",
      "Iter 248 time=0.11  loss=25.66    feature_norm=3619.88\n",
      "Iter 249 time=0.11  loss=23.54    feature_norm=3623.54\n",
      "Iter 250 time=0.11  loss=23.45    feature_norm=3627.20\n",
      "Iter 251 time=0.10  loss=21.73    feature_norm=3630.83\n",
      "Iter 252 time=0.11  loss=28.43    feature_norm=3634.46\n",
      "Iter 253 time=0.11  loss=28.89    feature_norm=3638.08\n",
      "Iter 254 time=0.11  loss=23.34    feature_norm=3641.70\n",
      "Iter 255 time=0.11  loss=23.76    feature_norm=3645.31\n",
      "Iter 256 time=0.11  loss=21.78    feature_norm=3648.90\n",
      "Iter 257 time=0.10  loss=17.78    feature_norm=3652.47\n",
      "Iter 258 time=0.11  loss=24.84    feature_norm=3656.03\n",
      "Iter 259 time=0.10  loss=23.97    feature_norm=3659.58\n",
      "Iter 260 time=0.11  loss=22.81    feature_norm=3663.12\n",
      "Iter 261 time=0.11  loss=22.64    feature_norm=3666.65\n",
      "Iter 262 time=0.10  loss=20.47    feature_norm=3670.16\n",
      "Iter 263 time=0.11  loss=20.27    feature_norm=3673.65\n",
      "Iter 264 time=0.11  loss=19.69    feature_norm=3677.13\n",
      "Iter 265 time=0.10  loss=15.78    feature_norm=3680.59\n",
      "Iter 266 time=0.10  loss=19.56    feature_norm=3684.04\n",
      "Iter 267 time=0.10  loss=17.71    feature_norm=3687.47\n",
      "Iter 268 time=0.10  loss=21.63    feature_norm=3690.89\n",
      "Iter 269 time=0.10  loss=14.88    feature_norm=3694.30\n",
      "Iter 270 time=0.11  loss=25.78    feature_norm=3697.69\n",
      "Iter 271 time=0.11  loss=23.70    feature_norm=3701.08\n",
      "Iter 272 time=0.11  loss=26.54    feature_norm=3704.46\n",
      "Iter 273 time=0.11  loss=21.94    feature_norm=3707.83\n",
      "Iter 274 time=0.10  loss=16.43    feature_norm=3711.19\n",
      "Iter 275 time=0.11  loss=24.78    feature_norm=3714.54\n",
      "Iter 276 time=0.11  loss=20.68    feature_norm=3717.87\n",
      "Iter 277 time=0.11  loss=18.69    feature_norm=3721.19\n",
      "Iter 278 time=0.11  loss=21.47    feature_norm=3724.50\n",
      "Iter 279 time=0.11  loss=23.93    feature_norm=3727.80\n",
      "Iter 280 time=0.10  loss=20.17    feature_norm=3731.10\n",
      "Iter 281 time=0.10  loss=18.99    feature_norm=3734.38\n",
      "Iter 282 time=0.11  loss=12.75    feature_norm=3737.65\n",
      "Iter 283 time=0.11  loss=22.67    feature_norm=3740.91\n",
      "Iter 284 time=0.11  loss=25.78    feature_norm=3744.15\n",
      "Iter 285 time=0.10  loss=15.59    feature_norm=3747.39\n",
      "Iter 286 time=0.11  loss=21.05    feature_norm=3750.61\n",
      "Iter 287 time=0.11  loss=22.34    feature_norm=3753.82\n",
      "Iter 288 time=0.11  loss=14.47    feature_norm=3757.02\n",
      "Iter 289 time=0.10  loss=17.36    feature_norm=3760.21\n",
      "Iter 290 time=0.11  loss=20.27    feature_norm=3763.38\n",
      "Iter 291 time=0.10  loss=20.84    feature_norm=3766.54\n",
      "Iter 292 time=0.10  loss=15.29    feature_norm=3769.69\n",
      "Iter 293 time=0.10  loss=16.91    feature_norm=3772.83\n",
      "Iter 294 time=0.10  loss=13.66    feature_norm=3775.95\n",
      "Iter 295 time=0.11  loss=9.87     feature_norm=3779.06\n",
      "Iter 296 time=0.10  loss=19.20    feature_norm=3782.15\n",
      "Iter 297 time=0.10  loss=14.35    feature_norm=3785.23\n",
      "Iter 298 time=0.10  loss=18.61    feature_norm=3788.30\n",
      "Iter 299 time=0.10  loss=13.29    feature_norm=3791.35\n",
      "Iter 300 time=0.11  loss=13.11    feature_norm=3794.39\n",
      "Total seconds required for training: 32.944\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 22913 (24925)\n",
      "Number of active attributes: 8005 (8840)\n",
      "Number of active labels: 28 (28)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "if param_num == 0:\n",
    "    crf_model = CRF(\n",
    "        algorithm=\"lbfgs\",\n",
    "        c1=0.01,\n",
    "        c2=0.01,\n",
    "        max_iterations=200,\n",
    "        all_possible_transitions=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "elif param_num == 1:\n",
    "    crf_model = CRF(\n",
    "        algorithm=\"ap\",\n",
    "        max_iterations=300,\n",
    "        all_possible_transitions=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "elif param_num == 2:\n",
    "    raise NotImplementedError\n",
    "\n",
    "\n",
    "if mode == \"train\":\n",
    "    crf_model.fit(x_train, y_train)\n",
    "    with open(f\"crf_{Language}{param_num}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(crf_model, f)\n",
    "elif mode == \"test\":\n",
    "    with open(f\"crf_{Language}{param_num}.pkl\", \"rb\") as f:\n",
    "        crf_model = pickle.load(f)\n",
    "\n",
    "\n",
    "if mode == \"train\":\n",
    "    y_pred = crf_model.predict(x_valid)\n",
    "    combined_data = combine_data([sentence for sentence, _ in valid_data], y_pred)\n",
    "elif mode == \"test\":\n",
    "    y_pred = crf_model.predict(x_test)\n",
    "    combined_data = combine_data([sentence for sentence, _ in test_data], y_pred)\n",
    "\n",
    "\n",
    "output_file = f\"output_{Language}.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.9423    0.9608    0.9515       102\n",
      "      M-NAME     0.9351    0.9600    0.9474        75\n",
      "      E-NAME     0.9515    0.9608    0.9561       102\n",
      "      S-NAME     1.0000    1.0000    1.0000         8\n",
      "      B-CONT     1.0000    1.0000    1.0000        33\n",
      "      M-CONT     1.0000    1.0000    1.0000        64\n",
      "      E-CONT     1.0000    1.0000    1.0000        33\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.9550    1.0000    0.9770       106\n",
      "       M-EDU     0.9465    1.0000    0.9725       177\n",
      "       E-EDU     0.9369    0.9811    0.9585       106\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.8929    0.8955    0.8942       689\n",
      "     M-TITLE     0.8821    0.8905    0.8863      1479\n",
      "     E-TITLE     0.9783    0.9826    0.9804       689\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.9363    0.9291    0.9327       522\n",
      "       M-ORG     0.9314    0.9481    0.9397      3622\n",
      "       E-ORG     0.8621    0.8621    0.8621       522\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     1.0000    1.0000    1.0000        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     1.0000    1.0000    1.0000        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         1\n",
      "       B-PRO     0.7500    0.8333    0.7895        18\n",
      "       M-PRO     0.7931    0.6970    0.7419        33\n",
      "       E-PRO     0.8947    0.9444    0.9189        18\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     0.5000    0.5000    0.5000         2\n",
      "       M-LOC     0.7500    0.5000    0.6000         6\n",
      "       E-LOC     1.0000    0.5000    0.6667         2\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.9208    0.9317    0.9262      8437\n",
      "   macro avg     0.6824    0.6670    0.6711      8437\n",
      "weighted avg     0.9206    0.9317    0.9260      8437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from NER.check import check\n",
    "\n",
    "if mode == \"train\":\n",
    "    report = check(\n",
    "        language=Language,\n",
    "        gold_path=f\"../NER/{Language}/validation.txt\",\n",
    "        my_path=output_file,\n",
    "    )\n",
    "elif mode == \"test\":\n",
    "    report = check(\n",
    "        language=Language,\n",
    "        gold_path=f\"../NER/{Language}/test.txt\",\n",
    "        my_path=output_file,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

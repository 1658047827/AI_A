{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "Language = \"English\"\n",
    "# Language = \"Chinese\"\n",
    "mode = \"train\"\n",
    "param_num = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-26 17:56:22,294 P19552 INFO train dataset size: 14041\n",
      "2023-11-26 17:56:22,295 P19552 INFO valid dataset size: 3250\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "from Part1.dataprocess import data_process, set_log, combine_data\n",
    "from sklearn_crf import sent2features\n",
    "\n",
    "\n",
    "set_log(None)\n",
    "train_data, valid_data, test_data = data_process(f\"../NER/{Language}\", mode=mode)\n",
    "\n",
    "x_train = [sent2features(sentence, Language, param_num) for sentence, _ in train_data]\n",
    "y_train = [label for _, label in train_data]\n",
    "x_valid = [sent2features(sentence, Language, param_num) for sentence, _ in valid_data]\n",
    "y_valid = [label for _, label in valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 14041/14041 [00:00<00:00, 15566.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 108083\n",
      "Seconds required: 0.212\n",
      "\n",
      "Averaged perceptron\n",
      "max_iterations: 300\n",
      "epsilon: 0.000000\n",
      "\n",
      "Iter 1   time=0.09  loss=2258.15  feature_norm=828.10\n",
      "Iter 2   time=0.08  loss=1480.59  feature_norm=1099.65\n",
      "Iter 3   time=0.08  loss=1229.77  feature_norm=1297.52\n",
      "Iter 4   time=0.08  loss=1068.97  feature_norm=1458.81\n",
      "Iter 5   time=0.07  loss=954.78   feature_norm=1598.40\n",
      "Iter 6   time=0.07  loss=825.02   feature_norm=1719.88\n",
      "Iter 7   time=0.07  loss=770.32   feature_norm=1828.63\n",
      "Iter 8   time=0.07  loss=719.65   feature_norm=1926.93\n",
      "Iter 9   time=0.07  loss=681.09   feature_norm=2017.71\n",
      "Iter 10  time=0.07  loss=651.48   feature_norm=2102.26\n",
      "Iter 11  time=0.07  loss=582.99   feature_norm=2181.32\n",
      "Iter 12  time=0.07  loss=572.69   feature_norm=2255.51\n",
      "Iter 13  time=0.07  loss=535.43   feature_norm=2325.31\n",
      "Iter 14  time=0.07  loss=500.81   feature_norm=2391.55\n",
      "Iter 15  time=0.07  loss=503.46   feature_norm=2454.66\n",
      "Iter 16  time=0.06  loss=473.54   feature_norm=2515.31\n",
      "Iter 17  time=0.06  loss=431.94   feature_norm=2573.53\n",
      "Iter 18  time=0.06  loss=419.83   feature_norm=2628.99\n",
      "Iter 19  time=0.07  loss=381.69   feature_norm=2681.95\n",
      "Iter 20  time=0.06  loss=367.82   feature_norm=2732.48\n",
      "Iter 21  time=0.06  loss=360.51   feature_norm=2781.17\n",
      "Iter 22  time=0.06  loss=355.76   feature_norm=2827.98\n",
      "Iter 23  time=0.06  loss=312.80   feature_norm=2873.05\n",
      "Iter 24  time=0.06  loss=302.00   feature_norm=2916.31\n",
      "Iter 25  time=0.06  loss=321.80   feature_norm=2958.23\n",
      "Iter 26  time=0.06  loss=301.02   feature_norm=2998.83\n",
      "Iter 27  time=0.06  loss=297.22   feature_norm=3038.25\n",
      "Iter 28  time=0.06  loss=265.42   feature_norm=3076.45\n",
      "Iter 29  time=0.06  loss=251.63   feature_norm=3113.33\n",
      "Iter 30  time=0.06  loss=254.91   feature_norm=3149.10\n",
      "Iter 31  time=0.06  loss=253.85   feature_norm=3183.93\n",
      "Iter 32  time=0.06  loss=240.22   feature_norm=3217.73\n",
      "Iter 33  time=0.06  loss=222.96   feature_norm=3250.46\n",
      "Iter 34  time=0.06  loss=224.33   feature_norm=3282.30\n",
      "Iter 35  time=0.06  loss=233.25   feature_norm=3313.41\n",
      "Iter 36  time=0.06  loss=222.63   feature_norm=3343.70\n",
      "Iter 37  time=0.06  loss=201.52   feature_norm=3373.25\n",
      "Iter 38  time=0.06  loss=168.17   feature_norm=3401.91\n",
      "Iter 39  time=0.06  loss=193.59   feature_norm=3429.83\n",
      "Iter 40  time=0.06  loss=165.99   feature_norm=3457.06\n",
      "Iter 41  time=0.06  loss=181.18   feature_norm=3483.57\n",
      "Iter 42  time=0.06  loss=149.47   feature_norm=3509.42\n",
      "Iter 43  time=0.06  loss=180.41   feature_norm=3534.62\n",
      "Iter 44  time=0.06  loss=151.72   feature_norm=3559.28\n",
      "Iter 45  time=0.06  loss=153.85   feature_norm=3583.38\n",
      "Iter 46  time=0.05  loss=153.24   feature_norm=3606.91\n",
      "Iter 47  time=0.06  loss=150.14   feature_norm=3629.90\n",
      "Iter 48  time=0.06  loss=131.73   feature_norm=3652.35\n",
      "Iter 49  time=0.06  loss=131.59   feature_norm=3674.24\n",
      "Iter 50  time=0.06  loss=133.05   feature_norm=3695.64\n",
      "Iter 51  time=0.06  loss=122.88   feature_norm=3716.55\n",
      "Iter 52  time=0.05  loss=132.91   feature_norm=3737.09\n",
      "Iter 53  time=0.05  loss=126.70   feature_norm=3757.16\n",
      "Iter 54  time=0.05  loss=120.33   feature_norm=3776.85\n",
      "Iter 55  time=0.06  loss=112.79   feature_norm=3796.14\n",
      "Iter 56  time=0.05  loss=120.76   feature_norm=3815.01\n",
      "Iter 57  time=0.05  loss=106.48   feature_norm=3833.51\n",
      "Iter 58  time=0.05  loss=120.98   feature_norm=3851.69\n",
      "Iter 59  time=0.05  loss=115.85   feature_norm=3869.58\n",
      "Iter 60  time=0.06  loss=119.21   feature_norm=3887.14\n",
      "Iter 61  time=0.06  loss=105.37   feature_norm=3904.38\n",
      "Iter 62  time=0.05  loss=112.28   feature_norm=3921.32\n",
      "Iter 63  time=0.05  loss=96.62    feature_norm=3937.94\n",
      "Iter 64  time=0.05  loss=115.15   feature_norm=3954.30\n",
      "Iter 65  time=0.06  loss=90.75    feature_norm=3970.35\n",
      "Iter 66  time=0.06  loss=82.58    feature_norm=3986.10\n",
      "Iter 67  time=0.05  loss=83.09    feature_norm=4001.55\n",
      "Iter 68  time=0.05  loss=95.99    feature_norm=4016.73\n",
      "Iter 69  time=0.05  loss=93.11    feature_norm=4031.68\n",
      "Iter 70  time=0.05  loss=90.61    feature_norm=4046.41\n",
      "Iter 71  time=0.05  loss=108.83   feature_norm=4060.94\n",
      "Iter 72  time=0.05  loss=89.41    feature_norm=4075.27\n",
      "Iter 73  time=0.05  loss=91.12    feature_norm=4089.41\n",
      "Iter 74  time=0.06  loss=89.79    feature_norm=4103.32\n",
      "Iter 75  time=0.06  loss=85.48    feature_norm=4117.02\n",
      "Iter 76  time=0.05  loss=73.56    feature_norm=4130.53\n",
      "Iter 77  time=0.05  loss=71.26    feature_norm=4143.80\n",
      "Iter 78  time=0.05  loss=72.83    feature_norm=4156.89\n",
      "Iter 79  time=0.05  loss=81.22    feature_norm=4169.76\n",
      "Iter 80  time=0.05  loss=85.75    feature_norm=4182.45\n",
      "Iter 81  time=0.05  loss=63.45    feature_norm=4194.95\n",
      "Iter 82  time=0.05  loss=74.93    feature_norm=4207.31\n",
      "Iter 83  time=0.05  loss=75.49    feature_norm=4219.47\n",
      "Iter 84  time=0.05  loss=57.87    feature_norm=4231.45\n",
      "Iter 85  time=0.05  loss=62.02    feature_norm=4243.24\n",
      "Iter 86  time=0.05  loss=60.30    feature_norm=4254.86\n",
      "Iter 87  time=0.05  loss=62.55    feature_norm=4266.29\n",
      "Iter 88  time=0.05  loss=58.45    feature_norm=4277.56\n",
      "Iter 89  time=0.05  loss=66.21    feature_norm=4288.68\n",
      "Iter 90  time=0.05  loss=46.48    feature_norm=4299.64\n",
      "Iter 91  time=0.05  loss=51.42    feature_norm=4310.44\n",
      "Iter 92  time=0.05  loss=53.33    feature_norm=4321.08\n",
      "Iter 93  time=0.05  loss=47.62    feature_norm=4331.57\n",
      "Iter 94  time=0.05  loss=54.81    feature_norm=4341.90\n",
      "Iter 95  time=0.05  loss=49.13    feature_norm=4352.08\n",
      "Iter 96  time=0.05  loss=51.01    feature_norm=4362.13\n",
      "Iter 97  time=0.05  loss=53.45    feature_norm=4372.04\n",
      "Iter 98  time=0.05  loss=60.65    feature_norm=4381.84\n",
      "Iter 99  time=0.05  loss=53.67    feature_norm=4391.51\n",
      "Iter 100 time=0.06  loss=54.83    feature_norm=4401.06\n",
      "Iter 101 time=0.05  loss=65.26    feature_norm=4410.51\n",
      "Iter 102 time=0.05  loss=50.86    feature_norm=4419.85\n",
      "Iter 103 time=0.05  loss=62.72    feature_norm=4429.09\n",
      "Iter 104 time=0.06  loss=49.32    feature_norm=4438.23\n",
      "Iter 105 time=0.05  loss=41.58    feature_norm=4447.25\n",
      "Iter 106 time=0.05  loss=41.89    feature_norm=4456.15\n",
      "Iter 107 time=0.05  loss=42.61    feature_norm=4464.93\n",
      "Iter 108 time=0.05  loss=43.98    feature_norm=4473.62\n",
      "Iter 109 time=0.05  loss=41.21    feature_norm=4482.21\n",
      "Iter 110 time=0.05  loss=37.67    feature_norm=4490.70\n",
      "Iter 111 time=0.05  loss=43.69    feature_norm=4499.09\n",
      "Iter 112 time=0.05  loss=46.12    feature_norm=4507.38\n",
      "Iter 113 time=0.05  loss=34.78    feature_norm=4515.56\n",
      "Iter 114 time=0.05  loss=59.20    feature_norm=4523.66\n",
      "Iter 115 time=0.05  loss=38.44    feature_norm=4531.68\n",
      "Iter 116 time=0.05  loss=67.29    feature_norm=4539.64\n",
      "Iter 117 time=0.05  loss=37.74    feature_norm=4547.53\n",
      "Iter 118 time=0.05  loss=35.70    feature_norm=4555.32\n",
      "Iter 119 time=0.05  loss=49.13    feature_norm=4563.02\n",
      "Iter 120 time=0.05  loss=37.05    feature_norm=4570.63\n",
      "Iter 121 time=0.05  loss=50.29    feature_norm=4578.16\n",
      "Iter 122 time=0.05  loss=35.02    feature_norm=4585.60\n",
      "Iter 123 time=0.05  loss=42.47    feature_norm=4592.96\n",
      "Iter 124 time=0.05  loss=43.58    feature_norm=4600.23\n",
      "Iter 125 time=0.05  loss=54.66    feature_norm=4607.45\n",
      "Iter 126 time=0.05  loss=37.54    feature_norm=4614.60\n",
      "Iter 127 time=0.05  loss=35.18    feature_norm=4621.69\n",
      "Iter 128 time=0.05  loss=30.35    feature_norm=4628.69\n",
      "Iter 129 time=0.05  loss=37.23    feature_norm=4635.63\n",
      "Iter 130 time=0.05  loss=40.57    feature_norm=4642.50\n",
      "Iter 131 time=0.05  loss=47.20    feature_norm=4649.32\n",
      "Iter 132 time=0.05  loss=39.88    feature_norm=4656.08\n",
      "Iter 133 time=0.05  loss=35.87    feature_norm=4662.78\n",
      "Iter 134 time=0.05  loss=37.75    feature_norm=4669.41\n",
      "Iter 135 time=0.05  loss=41.23    feature_norm=4675.98\n",
      "Iter 136 time=0.05  loss=42.96    feature_norm=4682.51\n",
      "Iter 137 time=0.05  loss=46.32    feature_norm=4688.99\n",
      "Iter 138 time=0.05  loss=47.93    feature_norm=4695.43\n",
      "Iter 139 time=0.05  loss=33.71    feature_norm=4701.82\n",
      "Iter 140 time=0.05  loss=38.82    feature_norm=4708.15\n",
      "Iter 141 time=0.05  loss=30.89    feature_norm=4714.43\n",
      "Iter 142 time=0.05  loss=45.62    feature_norm=4720.65\n",
      "Iter 143 time=0.05  loss=38.66    feature_norm=4726.83\n",
      "Iter 144 time=0.05  loss=50.54    feature_norm=4732.96\n",
      "Iter 145 time=0.05  loss=44.72    feature_norm=4739.05\n",
      "Iter 146 time=0.05  loss=29.86    feature_norm=4745.10\n",
      "Iter 147 time=0.05  loss=38.78    feature_norm=4751.09\n",
      "Iter 148 time=0.05  loss=25.79    feature_norm=4757.03\n",
      "Iter 149 time=0.05  loss=39.38    feature_norm=4762.91\n",
      "Iter 150 time=0.05  loss=37.79    feature_norm=4768.75\n",
      "Iter 151 time=0.05  loss=41.14    feature_norm=4774.55\n",
      "Iter 152 time=0.05  loss=42.12    feature_norm=4780.31\n",
      "Iter 153 time=0.05  loss=35.47    feature_norm=4786.03\n",
      "Iter 154 time=0.05  loss=45.37    feature_norm=4791.72\n",
      "Iter 155 time=0.05  loss=39.93    feature_norm=4797.37\n",
      "Iter 156 time=0.05  loss=24.21    feature_norm=4802.97\n",
      "Iter 157 time=0.05  loss=32.41    feature_norm=4808.53\n",
      "Iter 158 time=0.05  loss=29.97    feature_norm=4814.04\n",
      "Iter 159 time=0.05  loss=28.29    feature_norm=4819.50\n",
      "Iter 160 time=0.05  loss=32.78    feature_norm=4824.92\n",
      "Iter 161 time=0.05  loss=44.85    feature_norm=4830.31\n",
      "Iter 162 time=0.05  loss=32.96    feature_norm=4835.66\n",
      "Iter 163 time=0.05  loss=29.37    feature_norm=4840.96\n",
      "Iter 164 time=0.05  loss=28.06    feature_norm=4846.22\n",
      "Iter 165 time=0.05  loss=23.32    feature_norm=4851.43\n",
      "Iter 166 time=0.05  loss=38.26    feature_norm=4856.61\n",
      "Iter 167 time=0.05  loss=30.79    feature_norm=4861.75\n",
      "Iter 168 time=0.05  loss=31.13    feature_norm=4866.85\n",
      "Iter 169 time=0.05  loss=22.12    feature_norm=4871.91\n",
      "Iter 170 time=0.05  loss=27.88    feature_norm=4876.93\n",
      "Iter 171 time=0.05  loss=33.62    feature_norm=4881.92\n",
      "Iter 172 time=0.05  loss=27.89    feature_norm=4886.87\n",
      "Iter 173 time=0.05  loss=28.67    feature_norm=4891.78\n",
      "Iter 174 time=0.05  loss=34.48    feature_norm=4896.65\n",
      "Iter 175 time=0.05  loss=31.32    feature_norm=4901.50\n",
      "Iter 176 time=0.05  loss=29.66    feature_norm=4906.30\n",
      "Iter 177 time=0.05  loss=31.74    feature_norm=4911.08\n",
      "Iter 178 time=0.05  loss=30.16    feature_norm=4915.81\n",
      "Iter 179 time=0.05  loss=39.32    feature_norm=4920.53\n",
      "Iter 180 time=0.05  loss=21.02    feature_norm=4925.22\n",
      "Iter 181 time=0.05  loss=27.73    feature_norm=4929.87\n",
      "Iter 182 time=0.05  loss=24.77    feature_norm=4934.49\n",
      "Iter 183 time=0.05  loss=38.13    feature_norm=4939.08\n",
      "Iter 184 time=0.05  loss=19.02    feature_norm=4943.64\n",
      "Iter 185 time=0.05  loss=26.83    feature_norm=4948.16\n",
      "Iter 186 time=0.05  loss=27.68    feature_norm=4952.65\n",
      "Iter 187 time=0.05  loss=20.57    feature_norm=4957.11\n",
      "Iter 188 time=0.05  loss=24.52    feature_norm=4961.54\n",
      "Iter 189 time=0.05  loss=25.35    feature_norm=4965.93\n",
      "Iter 190 time=0.05  loss=26.98    feature_norm=4970.31\n",
      "Iter 191 time=0.05  loss=31.34    feature_norm=4974.65\n",
      "Iter 192 time=0.05  loss=30.59    feature_norm=4978.97\n",
      "Iter 193 time=0.05  loss=31.80    feature_norm=4983.26\n",
      "Iter 194 time=0.05  loss=35.57    feature_norm=4987.53\n",
      "Iter 195 time=0.05  loss=31.51    feature_norm=4991.77\n",
      "Iter 196 time=0.06  loss=34.72    feature_norm=4996.00\n",
      "Iter 197 time=0.05  loss=30.83    feature_norm=5000.20\n",
      "Iter 198 time=0.05  loss=31.07    feature_norm=5004.39\n",
      "Iter 199 time=0.05  loss=26.84    feature_norm=5008.54\n",
      "Iter 200 time=0.05  loss=14.66    feature_norm=5012.67\n",
      "Iter 201 time=0.05  loss=21.97    feature_norm=5016.77\n",
      "Iter 202 time=0.05  loss=19.42    feature_norm=5020.84\n",
      "Iter 203 time=0.05  loss=29.16    feature_norm=5024.88\n",
      "Iter 204 time=0.05  loss=15.61    feature_norm=5028.89\n",
      "Iter 205 time=0.05  loss=19.01    feature_norm=5032.88\n",
      "Iter 206 time=0.05  loss=23.19    feature_norm=5036.83\n",
      "Iter 207 time=0.05  loss=17.73    feature_norm=5040.76\n",
      "Iter 208 time=0.05  loss=21.49    feature_norm=5044.66\n",
      "Iter 209 time=0.05  loss=20.87    feature_norm=5048.53\n",
      "Iter 210 time=0.05  loss=23.88    feature_norm=5052.38\n",
      "Iter 211 time=0.05  loss=29.10    feature_norm=5056.21\n",
      "Iter 212 time=0.05  loss=25.48    feature_norm=5060.02\n",
      "Iter 213 time=0.05  loss=21.82    feature_norm=5063.80\n",
      "Iter 214 time=0.05  loss=19.92    feature_norm=5067.56\n",
      "Iter 215 time=0.05  loss=24.09    feature_norm=5071.29\n",
      "Iter 216 time=0.05  loss=28.74    feature_norm=5075.00\n",
      "Iter 217 time=0.05  loss=27.24    feature_norm=5078.70\n",
      "Iter 218 time=0.05  loss=19.12    feature_norm=5082.38\n",
      "Iter 219 time=0.05  loss=32.47    feature_norm=5086.04\n",
      "Iter 220 time=0.05  loss=17.84    feature_norm=5089.68\n",
      "Iter 221 time=0.05  loss=18.37    feature_norm=5093.29\n",
      "Iter 222 time=0.05  loss=14.56    feature_norm=5096.88\n",
      "Iter 223 time=0.05  loss=15.71    feature_norm=5100.45\n",
      "Iter 224 time=0.05  loss=21.16    feature_norm=5104.00\n",
      "Iter 225 time=0.05  loss=13.07    feature_norm=5107.52\n",
      "Iter 226 time=0.05  loss=23.14    feature_norm=5111.02\n",
      "Iter 227 time=0.05  loss=28.22    feature_norm=5114.50\n",
      "Iter 228 time=0.05  loss=17.72    feature_norm=5117.97\n",
      "Iter 229 time=0.05  loss=22.12    feature_norm=5121.41\n",
      "Iter 230 time=0.05  loss=18.12    feature_norm=5124.83\n",
      "Iter 231 time=0.05  loss=22.83    feature_norm=5128.24\n",
      "Iter 232 time=0.05  loss=17.42    feature_norm=5131.62\n",
      "Iter 233 time=0.05  loss=15.15    feature_norm=5134.99\n",
      "Iter 234 time=0.05  loss=18.60    feature_norm=5138.33\n",
      "Iter 235 time=0.05  loss=18.10    feature_norm=5141.66\n",
      "Iter 236 time=0.05  loss=15.01    feature_norm=5144.96\n",
      "Iter 237 time=0.05  loss=25.96    feature_norm=5148.24\n",
      "Iter 238 time=0.05  loss=12.05    feature_norm=5151.50\n",
      "Iter 239 time=0.05  loss=20.50    feature_norm=5154.74\n",
      "Iter 240 time=0.05  loss=22.58    feature_norm=5157.97\n",
      "Iter 241 time=0.05  loss=18.54    feature_norm=5161.17\n",
      "Iter 242 time=0.05  loss=20.92    feature_norm=5164.36\n",
      "Iter 243 time=0.05  loss=21.03    feature_norm=5167.53\n",
      "Iter 244 time=0.05  loss=15.10    feature_norm=5170.68\n",
      "Iter 245 time=0.05  loss=16.07    feature_norm=5173.82\n",
      "Iter 246 time=0.05  loss=13.06    feature_norm=5176.93\n",
      "Iter 247 time=0.05  loss=19.54    feature_norm=5180.03\n",
      "Iter 248 time=0.05  loss=17.36    feature_norm=5183.11\n",
      "Iter 249 time=0.05  loss=25.36    feature_norm=5186.17\n",
      "Iter 250 time=0.05  loss=17.62    feature_norm=5189.22\n",
      "Iter 251 time=0.05  loss=29.74    feature_norm=5192.25\n",
      "Iter 252 time=0.05  loss=23.81    feature_norm=5195.27\n",
      "Iter 253 time=0.05  loss=15.28    feature_norm=5198.27\n",
      "Iter 254 time=0.05  loss=16.99    feature_norm=5201.26\n",
      "Iter 255 time=0.05  loss=14.83    feature_norm=5204.23\n",
      "Iter 256 time=0.05  loss=19.05    feature_norm=5207.19\n",
      "Iter 257 time=0.05  loss=17.07    feature_norm=5210.13\n",
      "Iter 258 time=0.05  loss=24.78    feature_norm=5213.05\n",
      "Iter 259 time=0.05  loss=22.81    feature_norm=5215.97\n",
      "Iter 260 time=0.05  loss=21.00    feature_norm=5218.87\n",
      "Iter 261 time=0.05  loss=17.51    feature_norm=5221.75\n",
      "Iter 262 time=0.05  loss=24.03    feature_norm=5224.63\n",
      "Iter 263 time=0.05  loss=19.24    feature_norm=5227.49\n",
      "Iter 264 time=0.05  loss=17.26    feature_norm=5230.34\n",
      "Iter 265 time=0.05  loss=16.14    feature_norm=5233.17\n",
      "Iter 266 time=0.05  loss=24.82    feature_norm=5235.99\n",
      "Iter 267 time=0.05  loss=18.97    feature_norm=5238.80\n",
      "Iter 268 time=0.05  loss=11.84    feature_norm=5241.60\n",
      "Iter 269 time=0.05  loss=14.79    feature_norm=5244.38\n",
      "Iter 270 time=0.05  loss=18.96    feature_norm=5247.15\n",
      "Iter 271 time=0.05  loss=14.33    feature_norm=5249.90\n",
      "Iter 272 time=0.05  loss=17.60    feature_norm=5252.63\n",
      "Iter 273 time=0.05  loss=15.82    feature_norm=5255.35\n",
      "Iter 274 time=0.05  loss=14.14    feature_norm=5258.06\n",
      "Iter 275 time=0.05  loss=23.67    feature_norm=5260.75\n",
      "Iter 276 time=0.05  loss=16.18    feature_norm=5263.43\n",
      "Iter 277 time=0.05  loss=22.74    feature_norm=5266.10\n",
      "Iter 278 time=0.05  loss=15.72    feature_norm=5268.76\n",
      "Iter 279 time=0.05  loss=13.86    feature_norm=5271.40\n",
      "Iter 280 time=0.05  loss=18.12    feature_norm=5274.03\n",
      "Iter 281 time=0.05  loss=15.33    feature_norm=5276.65\n",
      "Iter 282 time=0.05  loss=20.55    feature_norm=5279.25\n",
      "Iter 283 time=0.05  loss=24.86    feature_norm=5281.85\n",
      "Iter 284 time=0.05  loss=18.13    feature_norm=5284.43\n",
      "Iter 285 time=0.05  loss=20.97    feature_norm=5287.01\n",
      "Iter 286 time=0.05  loss=19.90    feature_norm=5289.57\n",
      "Iter 287 time=0.05  loss=13.75    feature_norm=5292.12\n",
      "Iter 288 time=0.05  loss=15.84    feature_norm=5294.65\n",
      "Iter 289 time=0.05  loss=14.14    feature_norm=5297.17\n",
      "Iter 290 time=0.05  loss=15.14    feature_norm=5299.68\n",
      "Iter 291 time=0.05  loss=20.26    feature_norm=5302.18\n",
      "Iter 292 time=0.05  loss=15.82    feature_norm=5304.67\n",
      "Iter 293 time=0.05  loss=14.50    feature_norm=5307.15\n",
      "Iter 294 time=0.05  loss=16.10    feature_norm=5309.61\n",
      "Iter 295 time=0.05  loss=17.94    feature_norm=5312.07\n",
      "Iter 296 time=0.05  loss=12.79    feature_norm=5314.51\n",
      "Iter 297 time=0.05  loss=16.30    feature_norm=5316.94\n",
      "Iter 298 time=0.05  loss=17.83    feature_norm=5319.36\n",
      "Iter 299 time=0.05  loss=13.63    feature_norm=5321.77\n",
      "Iter 300 time=0.05  loss=24.59    feature_norm=5324.17\n",
      "Total seconds required for training: 15.826\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 66109 (108083)\n",
      "Number of active attributes: 49470 (90427)\n",
      "Number of active labels: 9 (9)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.043\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "if param_num == 0:\n",
    "    crf_model = CRF(\n",
    "        algorithm=\"lbfgs\",\n",
    "        c1=0.01,\n",
    "        c2=0.01,\n",
    "        max_iterations=200,\n",
    "        all_possible_transitions=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "elif param_num == 1:\n",
    "    crf_model = CRF(\n",
    "        algorithm=\"ap\",\n",
    "        max_iterations=300,\n",
    "        all_possible_transitions=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "elif param_num == 2:\n",
    "    raise NotImplementedError\n",
    "\n",
    "crf_model.fit(x_train, y_train)\n",
    "with open(f\"crf_{Language}{param_num}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(crf_model, f)\n",
    "\n",
    "y_pred = crf_model.predict(x_valid)\n",
    "combined_data = combine_data([sentence for sentence, _ in valid_data], y_pred)\n",
    "\n",
    "output_file = f\"output_{Language}.txt\"\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.9062    0.9175    0.9118      1842\n",
      "       I-PER     0.9516    0.9472    0.9494      1307\n",
      "       B-ORG     0.8672    0.8233    0.8447      1341\n",
      "       I-ORG     0.8666    0.8389    0.8525       751\n",
      "       B-LOC     0.9226    0.9020    0.9122      1837\n",
      "       I-LOC     0.9231    0.8405    0.8798       257\n",
      "      B-MISC     0.9130    0.8427    0.8765       922\n",
      "      I-MISC     0.9055    0.7197    0.8019       346\n",
      "\n",
      "   micro avg     0.9086    0.8789    0.8935      8603\n",
      "   macro avg     0.9070    0.8540    0.8786      8603\n",
      "weighted avg     0.9083    0.8789    0.8928      8603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from NER.check import check\n",
    "\n",
    "report = check(\n",
    "    language=Language,\n",
    "    gold_path=f\"../NER/{Language}/validation.txt\",\n",
    "    my_path=output_file,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先导入相关的 `module` 、`class` 和 `function` 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from dataset import CharDataset, ToTensor\n",
    "from utils import DataLoader\n",
    "from init import seed_everything, dump_args, data_preprocess\n",
    "from model import MLPClassifier, accuracy\n",
    "from nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着使用 `args` 存储相关的参数，同时使用 `dump_args` 导出本次运行的参数到文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"epoches\"] = 80\n",
    "args[\"batch_size\"] = 32\n",
    "args[\"learning_rate\"] = 0.03\n",
    "args[\"record_path\"] = \"./record/char\"\n",
    "args[\"save_path\"] = \"./save/char/best_model.pkl\"\n",
    "args[\"raw_data_path\"] = \"./data/char/train_raw\"\n",
    "args[\"data_path\"] = \"./data/char/data.npz\"\n",
    "args[\"random_seed\"] = 42\n",
    "args[\"mode\"] = \"train_and_test\"  # [\"train\", \"test\", \"train_and_test\"]\n",
    "\n",
    "record_path = dump_args(args, args[\"record_path\"], False, args[\"mode\"])  # 如果要保存到日志文件，须设置参数 log=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 `seed_everything` 设置随机数种子，确保整个过程可重复。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(args[\"random_seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尝试加载训练数据，如果训练数据不存在，则通过 `data_preprocess` 生成。加载数据后初始化训练集和验证集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(args[\"data_path\"]):\n",
    "    data_preprocess(args[\"raw_data_path\"], args[\"data_path\"], shuffle=True)\n",
    "data_npz = np.load(args[\"data_path\"])\n",
    "\n",
    "transform = ToTensor()\n",
    "\n",
    "dataset_train = CharDataset(data_npz[\"x_train\"], data_npz[\"y_train\"], transform)\n",
    "dataloader_train = DataLoader(dataset_train, args[\"batch_size\"], shuffle=True)\n",
    "\n",
    "dataset_valid = CharDataset(data_npz[\"x_valid\"], data_npz[\"y_valid\"], transform)\n",
    "dataloader_valid = DataLoader(dataset_valid, args[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化分类器对象，然后尝试加载预训练的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MLPClassifier(28 * 28, 12)\n",
    "if os.path.exists(args[\"save_path\"]):\n",
    "    classifier.load_model(args[\"save_path\"])\n",
    "    print(classifier.best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接着根据当前的 `args[\"mode\"]` 判断是否进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"mode\"] == \"train\" or args[\"mode\"] == \"train_and_test\":\n",
    "    classifier.fit(\n",
    "        train_loader=dataloader_train,\n",
    "        valid_loader=dataloader_valid,\n",
    "        epoches=args[\"epoches\"],\n",
    "        learning_rate=args[\"learning_rate\"],\n",
    "        save_path=args[\"save_path\"],\n",
    "        log_interval=5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后可以进行测试集上的测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"mode\"] != \"test\" and args[\"mode\"] != \"train_and_test\":\n",
    "    exit(0)\n",
    "\n",
    "raw_test_path = \"\"\n",
    "test_path = \"\"\n",
    "if not os.path.exists(test_path):\n",
    "    data_preprocess(raw_test_path, test_path, shuffle=True)\n",
    "test_npz = np.load(test_path)\n",
    "\n",
    "dataset_test = CharDataset(test_npz[\"x_test\"], test_npz[\"y_test\"], transform)\n",
    "dataloader_test = DataLoader(dataset_test, args[\"batch_size\"], shuffle=False)\n",
    "\n",
    "loss = 0.0\n",
    "acc = 0.0\n",
    "loss_func = CrossEntropyLoss()\n",
    "for batch in dataloader_test:\n",
    "    result = classifier.predict(batch[\"x\"])\n",
    "    loss += loss_func(result[\"predicts\"], batch[\"y\"])\n",
    "    acc += accuracy(result[\"predicts\"], batch[\"y\"])\n",
    "loss /= len(dataloader_test)\n",
    "acc /= len(dataloader_test)\n",
    "logging.info(\"Test mean loss: {:.6f}, mean accuracy: {:.6f}\".format(loss, acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "73f83993ecc2dce571ce89cddd8a44e114591bb14d9f1f8465ac4f80026585cd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.18 ('AI_A')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
